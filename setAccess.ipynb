{"cells":[{"cell_type":"code","source":["storageAccountName=\"datalakestgentwo\"  # my storage (Azure Data Lake Storage Gen2)\naccessKey=dbutils.secrets.get(  # Access-Key to storage account - stored in backed-secret-scope of Databricks\n    scope=\"my-secret-databricks-scope\",\n    key=\"datalakestgentwoAccessKey\"\n)\ncontainer=\"mb-test-task\"\n\n# directories for each Data Lake layer (raw, cleansed, curated) and other usages\ndirs={\n    \"config\": \"config/\",\n    \"lvl1\": \"lvl1-raw/\",  # DataFactory-triggered container\n    \"lvl1-rejected\": \"lvl1-raw/rejected/\",\n    \"lvl2\": \"lvl2-cleansed/\",\n    \"lvl3\": \"lvl3-curated/\",\n    \"lvl3-dashboard\": \"lvl3-curated/dashboard/\",\n    \"test\": \"testsourcefiles/\"  # for further test purposes [generating the pipeline's trigger by copying file FROM \"(...)testSourceFiles\" TO \"(...)lvl1-raw\" container] - see the last cell in this notebook\n}\n\n# set access\nspark.conf.set(\n    \"fs.azure.account.key.\"+storageAccountName+\".dfs.core.windows.net\",\n    accessKey\n)"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"402d93ce-b308-402f-955b-8eb0c65df23c"}},"outputs":[],"execution_count":0}],"metadata":{"application/vnd.databricks.v1+notebook":{"notebookName":"setAccess","dashboards":[],"notebookMetadata":{"pythonIndentUnit":4},"language":"python","widgets":{},"notebookOrigID":1260026330619460}},"nbformat":4,"nbformat_minor":0}
